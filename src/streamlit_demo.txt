"""
- Avoid blocking: do face detection only every N frames and cache overlay.
- Fallback to OpenCV Haar cascade if MTCNN is slow/unavailable.
"""


import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase
import av
import cv2
import numpy as np
from PIL import Image
import time

# Optional fast detector imports
try:
    from mtcnn import MTCNN
    _HAS_MTCNN = True
except Exception:
    _HAS_MTCNN = False

st.set_page_config(page_title="∀I-SAGE Live Demo", layout="wide")
st.title("∀I-SAGE — Live Face Attribute Demo")
st.markdown(
    """
    Allow camera. This demo requests 1280×720 resolution and draws live bounding boxes.
    If the camera or browser cannot supply 1280×720 it will use the best available resolution.
    """
)

# Media constraints request (ask browser for 1280x720)
MEDIA_CONSTRAINTS = {
    "video": {
        "width": {"ideal": 1280},
        "height": {"ideal": 720},
        "frameRate": {"ideal": 30}
    },
    "audio": False
}

# Detection settings
PROCESS_EVERY_N_FRAMES = 3  # only run detection every N frames => much faster overall
DRAW_BOX_COLOR = (0, 255, 0)
TEXT_COLOR = (255, 255, 255)
TEXT_BG = (0, 0, 0)

# Try to initialize detectors once (inside the transformer too)
def create_fast_cascade():
    # Use OpenCV's prebuilt frontal face haarcascade (fast)
    cascade = None
    try:
        cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")
        if cascade.empty():
            cascade = None
    except Exception:
        cascade = None
    return cascade

class Transformer(VideoTransformerBase):
    def __init__(self):
        # Use one detector instance per transformer
        self.frame_count = 0
        self.last_overlay = None  # cache last drawn image to return quickly
        self.last_detection_time = 0.0

        # Prefer MTCNN if available, otherwise Haar
        self.use_mtcnn = False
        self.mtcnn = None
        if _HAS_MTCNN:
            try:
                # instantiate but don't rely on it being super-fast
                self.mtcnn = MTCNN()
                self.use_mtcnn = True
            except Exception:
                self.mtcnn = None
                self.use_mtcnn = False

        self.haar = create_fast_cascade()

    def detect_faces_mtcnn(self, img_rgb):
        # MTCNN expects RGB numpy array
        try:
            faces = self.mtcnn.detect_faces(img_rgb)
        except Exception:
            faces = []
        return faces

    def detect_faces_haar(self, img_gray, scaleFactor=1.1, minNeighbors=5):
        rects = []
        if self.haar is None:
            return rects
        faces = self.haar.detectMultiScale(img_gray, scaleFactor=scaleFactor, minNeighbors=minNeighbors, minSize=(30, 30))
        for (x, y, w, h) in faces:
            rects.append({"box": [int(x), int(y), int(w), int(h)], "confidence": 0.9})
        return rects

    def transform(self, frame: av.VideoFrame) -> av.VideoFrame:
        # Convert av frame -> RGB ndarray
        img = frame.to_ndarray(format="rgb24")  # shape HxWx3, RGB
        h, w, _ = img.shape
        self.frame_count += 1

        # Always start with a copy so we can return quickly if not processing
        display_img = img.copy()

        # If we have a cached overlay for this frame size, return it quickly
        # (but we still occasionally refresh)
        should_process = (self.frame_count % PROCESS_EVERY_N_FRAMES == 0)

        # If cached exists and we are not processing, return cached (fast)
        if (not should_process) and (self.last_overlay is not None):
            # If resolution changed, invalidate cache
            if self.last_overlay.shape[:2] == display_img.shape[:2]:
                return av.VideoFrame.from_ndarray(self.last_overlay, format="rgb24")
            else:
                self.last_overlay = None  # resolution changed; recompute below

        # Do detection (MTCNN preferred, otherwise Haar)
        faces = []
        if should_process:
            self.last_detection_time = time.time()
            if self.use_mtcnn and (self.mtcnn is not None):
                try:
                    # mtcnn wants RGB numpy array
                    faces = self.detect_faces_mtcnn(img)
                except Exception:
                    faces = []
            # If no faces detected with MTCNN or MTCNN not available, try Haar
            if (not faces) and (self.haar is not None):
                gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
                faces = self.detect_faces_haar(gray)

        # Draw boxes and labels on display_img
        if faces:
            for f in faces:
                box = f.get("box", None)
                if box is None:
                    continue
                x, y, w_box, h_box = box
                x, y = max(0, x), max(0, y)
                x2, y2 = x + w_box, y + h_box
                cv2.rectangle(display_img, (x, y), (x2, y2), DRAW_BOX_COLOR, 2)

                # simple confidence label (if available)
                conf = f.get("confidence", None)
                if conf is not None:
                    text = f"{conf:.2f}"
                    # putText uses BGR, but our array is RGB so give reversed color
                    cv2.putText(display_img, text, (x, max(0, y-8)),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, TEXT_COLOR, 1, cv2.LINE_AA)

        # Cache the overlay so subsequent frames can return it fast
        self.last_overlay = display_img

        # Return av frame
        return av.VideoFrame.from_ndarray(display_img, format="rgb24")


# Start the webrtc streamer with the requested media constraints
webrtc_ctx = webrtc_streamer(
    key="facesense-live",
    video_transformer_factory=Transformer,
    media_stream_constraints=MEDIA_CONSTRAINTS,
    async_transform=True,
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
)

st.caption("If the video freezes or resolution is low: close other apps using the camera (Zoom/Teams) and reload the page. If your camera doesn't support 1280×720, the browser will choose the closest supported resolution.")
